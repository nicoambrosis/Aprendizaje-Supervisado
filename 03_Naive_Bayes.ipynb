{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un archivo que tiene los datos ya curados de 5572 correos electronicos con el texto de esos correos y clasificados como SPAM o HAM (en la jerga de los correos electronicos son los correos deseados).\n",
    "\n",
    "El objetivo de esta notebook es entrenar un modelo de aprendizaje automatico utilizando el algoritmo de Naive Bayes para clasificar futuros correos electronicos como 'HAM' o 'SPAM'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "El archivo spam_or_ham.txt tiene que estar en la misma carpeta en donde se esta corriendo esta notebook. Caso contrario modificar la linea correspondiente en donde se carga el archivo y se lo almacena como una DF en la variable `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (5572, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_table(\"spam_or_ham.txt\", header=None, names=[\"target\", \"text\"])\n",
    "type(dataset), dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "target      \n",
       "ham     4825\n",
       "spam     747"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuantos correos tenemos de cada tipo?\n",
    "(dataset\n",
    " .groupby('target')\n",
    " .count()\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que nuestro dataset esta un poco desvalanceado. Hay muchos mas correos clasificados como HAM que como SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham:\n",
      "Nah I don't think he goes to usf, he lives around here though\n",
      "spam:\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos al azar un correo que haya sido clasificado como HAM y otro que haya sido clasificado como SPAM\n",
    "print('ham:')\n",
    "print(dataset.iloc[4,1])\n",
    "print('spam:')\n",
    "print(dataset.iloc[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CountVectorizer()`\n",
    "\n",
    "Transform the input from text into a bag of words matrix ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instanciamos la clase CountVectorizer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 2. Aplicamos el metodo fit_transform (learn the vocabulary dictionary and return document-term matrix).\n",
    "vectorized_data = vectorizer.fit_transform(dataset.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['huge', 'hugging', 'hugh', 'hugs', 'huh', 'hui', 'huiming', 'hum',\n",
       "       'humanities', 'humans', 'hun', 'hundred', 'hundreds', 'hungover',\n",
       "       'hungry', 'hunks', 'hunny', 'hunt', 'hunting', 'hurricanes',\n",
       "       'hurried', 'hurry', 'hurt', 'hurting', 'hurts', 'husband',\n",
       "       'hussey', 'hustle', 'hut', 'hv', 'hv9d', 'hvae', 'hw', 'hyde',\n",
       "       'hype', 'hypertension', 'hypotheticalhuagauahahuagahyuhagga',\n",
       "       'iam', 'ias', 'ibh', 'ibhltd', 'ibiza', 'ibm', 'ibn', 'ibored',\n",
       "       'ibuprofens', 'ic', 'iccha', 'ice', 'icic', 'icicibank', 'icky',\n",
       "       'icmb3cktz8r7', 'icon', 'id', 'idc', 'idea', 'ideal', 'ideas',\n",
       "       'identification', 'identifier', 'idew', 'idiot', 'idk', 'idps',\n",
       "       'idu', 'ie', 'if', 'iff', 'ifink', 'ig11', 'ignorant', 'ignore',\n",
       "       'ignoring', 'ihave', 'ijust', 'ikea', 'ikno', 'iknow', 'il',\n",
       "       'ileave', 'ill', 'illness', 'illspeak', 'ilol', 'im', 'image',\n",
       "       'images', 'imagination', 'imagine', 'imat', 'imf', 'img', 'imin',\n",
       "       'imma', 'immed', 'immediately', 'immunisation', 'imp', 'impatient'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usamos el metodo get_feature_names_out() para ver una parte de la bolsa de palabras que obtuvimos.\n",
    "# get_feature_names_out(): Get output feature names for transformation\n",
    "vectorizer.get_feature_names_out()[4000:4100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 8713), scipy.sparse.csr.csr_matrix)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data.shape, type(vectorized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vectorized_data` es la matriz (**sparsa**) que obtuvimos como producto de aplicar la clase `CountVectorizer()` a los datos de la columna `text` de nuestro dataset.\n",
    "- Cada columna de esta matriz corresponde a una palabra encontrada en los correos electronicos.\n",
    "- Las palabras estan ordenadas alfabeticamente\n",
    "- Cada fila de la matriz corresponde a uno de los correos electronicos. Se mantiene el mismo indice que los correos tiene en la DF `dataset`\n",
    "- Cada celda de la matriz contiene un numero entero que representa el numero de veces que esa palabra aparece en el mail correspondiente a esa fila. Si la palabra no esta en el mail, el valor es cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8713 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 74169 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que `vectorized_data` es una matriz esparsa, no podemos visualizarla en forma directa. Para poder hacerlo tenemos que utilizar el metodo `.to_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64),\n",
       " (5572, 8713))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data.toarray(), vectorized_data.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos los datos en conjunto de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, dataset.target, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 8713), (4457,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1115, 8713), (1115,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MultinomialNB()`\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instanciamos la clase MultinominalNM, es decir, elegimos el modelo que luego vamos a entrenar\n",
    "m_nb_clf = MultinomialNB() #dejamos los hiperparametros que vienen predeterminados\n",
    "\n",
    "# 2. Entrenamos el modelo usando los datos de entrenamiento\n",
    "m_nb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3855.,  602.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb_clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de las celdas anteriores indican que el modelo fue entrenado usando 3855 mails HAM y 602 mails SPAM. Nuevamente vemos que hay una diferencia importante en el numero de observaciones de cada clase. Esto podria traer algunos problemas para generalizar el uso de este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del modelo `m_nb_clf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algún caso en particular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busquemos una entrada spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961     ham\n",
       "3028     ham\n",
       "3593     ham\n",
       "2532     ham\n",
       "3943     ham\n",
       "3111    spam\n",
       "3272    spam\n",
       "3742    spam\n",
       "4281    spam\n",
       "4296    spam\n",
       "4335     ham\n",
       "642      ham\n",
       "714      ham\n",
       "3568    spam\n",
       "2868     ham\n",
       "3223     ham\n",
       "536      ham\n",
       "1077     ham\n",
       "1030     ham\n",
       "2780     ham\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analizamos al azar 20 observaciones del grupo de entrenamiento\n",
    "y_train.sample(20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero comparemos a mano si nuestro clasificador está prediciendo correctamente ese dato del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caso = 3272 #es un mail que fue etiquetado como spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new voicemail. Please call 08719181...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "3272   spam  You have 1 new voicemail. Please call 08719181..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[[caso]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb_clf.predict(vectorized_data[caso])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mail 3272 de la lista es clasificado por nuestro modelo `m_nb_clf` como spam. Coincide con la clasificacion original que tenia el mail, con los cual nuestro clasificador lo esta clasificando correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869     spam\n",
       "4729     ham\n",
       "2430    spam\n",
       "2570     ham\n",
       "2318     ham\n",
       "1940    spam\n",
       "4213    spam\n",
       "2236     ham\n",
       "1290     ham\n",
       "2196     ham\n",
       "228      ham\n",
       "3132    spam\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = m_nb_clf.predict(X_test) != y_test \n",
    "y_test_wrong_clf = y_test[condition]\n",
    "y_test_wrong_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e-mails that were not well classified by our model\n",
      "\n",
      "**************************************************\n",
      "e-mail # 869, Labeled as: spam\t| Classified as: ham \n",
      "Poba 'ham':0.9999879550279138\t| Poba 'spam':1.2044972084231873e-05\n",
      "Hello. We need some posh birds and chaps to user trial prods for champneys. Can i put you down? I need your address and dob asap. Ta r\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 4729, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.1663671224806417\t| Poba 'spam':0.83363287751935\n",
      "I (Career Tel) have added u as a contact on INDYAROCKS.COM to send FREE SMS. To remove from phonebook - sms NO to  &lt;#&gt;\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 2430, Labeled as: spam\t| Classified as: ham \n",
      "Poba 'ham':0.9723363000469025\t| Poba 'spam':0.027663699953083324\n",
      "Guess who am I?This is the first time I created a web page WWW.ASJESUS.COM read all I wrote. I'm waiting for your opinions. I want to be your friend 1/1\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 2570, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.02165427816327504\t| Poba 'spam':0.9783457218367239\n",
      "Ultimately tor motive tui achieve korli.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 2318, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':1.3846090543613059e-05\t| Poba 'spam':0.9999861539094668\n",
      "Waqt se pehle or naseeb se zyada kisi ko kuch nahi milta,Zindgi wo nahi he jo hum sochte hai Zindgi wo hai jo ham jeetey hai..........\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 1940, Labeled as: spam\t| Classified as: ham \n",
      "Poba 'ham':0.9589535497013584\t| Poba 'spam':0.04104645029863882\n",
      "More people are dogging in your area now. Call 09090204448 and join like minded guys. Why not arrange 1 yourself. There's 1 this evening. A£1.50 minAPN LS278BB\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 4213, Labeled as: spam\t| Classified as: ham \n",
      "Poba 'ham':0.9958870793377576\t| Poba 'spam':0.004112920662245603\n",
      "Missed call alert. These numbers called but left no message. 07008009200\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 2236, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.18772733673392528\t| Poba 'spam':0.8122726632660836\n",
      "Si.como no?!listened2the plaid album-quite gd&the new air1 which is hilarious-also boughtbraindancea comp.ofstuff on aphexs ;abel,u hav2hear it!c u sn xxxx\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 1290, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.0003589334006802751\t| Poba 'spam':0.99964106659932\n",
      "Hey...Great deal...Farm tour 9am to 5pm $95/pax, $50 deposit by 16 May\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 2196, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.39456700747431006\t| Poba 'spam':0.6054329925256926\n",
      "V-aluable. A-ffectionate. L-oveable. E-ternal. N-oble. T-ruthful. I-ntimate. N-atural. E-namous. Happy \"VALENTINES DAY\" in advance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 228, Labeled as: ham\t| Classified as: spam \n",
      "Poba 'ham':0.23306297778737556\t| Poba 'spam':0.7669370222126267\n",
      "Hey company elama po mudyadhu.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "e-mail # 3132, Labeled as: spam\t| Classified as: ham \n",
      "Poba 'ham':0.8431038027189457\t| Poba 'spam':0.15689619728105797\n",
      "LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('e-mails that were not well classified by our model\\n')\n",
    "print('*'*50)\n",
    "\n",
    "for i in y_test_wrong_clf.index:\n",
    "    print(f'e-mail # {i}, Labeled as: {dataset.iloc[i].target}\\t| Classified as: {m_nb_clf.predict(vectorized_data[i])[0]} ')\n",
    "    proba = np.exp(m_nb_clf.predict_log_proba(vectorized_data[i]))\n",
    "    print(f\"Poba 'ham':{proba[0][0]}\\t| Poba 'spam':{proba[0][1]}\")\n",
    "    print(dataset.iloc[i].text)\n",
    "    print('-'*120 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que muchos de los correos que aparecen como mal clasificados era correos que tambien hubiera sido dificil clasificadar para una persona. Por lo tanto, si bien el modelo cometio algunos errores, no parece ser tan grave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# una forma mas directa de ver si el caso esta bien clasificado\n",
    "caso_n = 322 # se puede ir variando este numero para ver el cualquier caso deseado\n",
    "m_nb_clf.predict(vectorized_data)[caso_n] == dataset.target[caso_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `predict_log_proba()`\n",
    "Podemos obtener la probabilidad de que haya sido spam o ham:\n",
    "\n",
    "Esta funcion devuelve como resultado el logaritmo natural de la probabilidad, por lo tanto para obtener la probabilidad tenemos que transformarlo aplicando e**(predict_log_proba()) o lo que es igual np.exp(predict_log_proba())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01501237, 0.98498763]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(m_nb_clf.predict_log_proba(vectorized_data[caso]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb_clf.predict(vectorized_data)[caso_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la probabilidad de spam es mayor que la de ham. Veamos lo mismo pero para un caso que no era spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham Ugh my leg hurts. Musta overdid it on mon.\n",
      "[[9.99957311e-01 4.26892776e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(*dataset.iloc[5199])\n",
    "print(np.exp(m_nb_clf.predict_log_proba(vectorized_data[5199])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la probabilidad de ham es mayor que la de spam, por eso lo clasifica como ham.\n",
    "\n",
    "Veamos algunos casos del conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095     True\n",
       "5343     True\n",
       "564      True\n",
       "3849     True\n",
       "3317     True\n",
       "5277     True\n",
       "1674     True\n",
       "3753     True\n",
       "5507     True\n",
       "265      True\n",
       "4413     True\n",
       "5111     True\n",
       "4896     True\n",
       "3161     True\n",
       "3743     True\n",
       "2887     True\n",
       "869     False\n",
       "4061     True\n",
       "1072     True\n",
       "4559     True\n",
       "Name: target, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nb_clf.predict(X_test)[:20] == y_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `classification_report()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       970\n",
      "        spam       0.95      0.97      0.96       145\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.97      0.98      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, m_nb_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label a negative sample as positive.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `confusion_matrix()`\n",
    "\n",
    "Usamos [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_test_pred = m_nb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[963,   7],\n",
       "       [  5, 140]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_test_pred, labels=['ham', 'spam'])\n",
    "confusion_matrix\n",
    "# array = metrics.confusion_matrix(df_test[\"class\"], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix, [\"ham\",\"spam\"], \n",
    "[\"ham\",\"spam\"]) \n",
    "\n",
    "plt.figure()\n",
    "# sns.set(font_scale=1.4)#for label size \n",
    "sns.heatmap(df_cm,\n",
    "            cmap = 'Blues',\n",
    "            annot=True,\n",
    "            annot_kws={\"size\": 14},\n",
    "            fmt='g',\n",
    "            linecolor = 'white',\n",
    "            linewidths = 0.5)\n",
    "plt.title('Confussion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es otra forma de visualizar los resultados obtenidos al aplicar nuestro modelo a los datos de test:\n",
    "- hay 7 e-mails que estaban etiquetados como ham que fueron clasiicados como spam\n",
    "- hay 5 e-mails que estaban etiquetados como spam y fueron clasificados como ham"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "98b921049c439807c081d6616d9731da5920d3b6edca6190edeae5a80cc907f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
